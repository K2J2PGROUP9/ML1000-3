---
title: Toronto Airbnb data research. Application of Supervised Learning Methods and Unsupervised Learning Methods
author:
  - name: Ketao Li
    affiliation: York University
    email:  liketao@yahoo.com
  - name: Kush Halani
    affiliation: York University
    email:  kush.halani@ontariotechu.net
  - name: Josue Romain
    affiliation: York University
    email:  josue.rolland.romain@gmail.com    
  - name: Juan Peña
    affiliation: York University
    email:  jppena62@my.yorku.ca
 
abstract: >
  From thousands of listings in different cities, Airbnb has become a massive sink of information. Data provided by homeowners are often big, messy, yet, extremely useful. The goal of this project is to extract knowledge from these datasets by applying techniques and methodologies common in data mining.As more homeowners put their properties on the platform, Airbnb is able to suggest appropriate prices for the listings based on machine learning models trained over large sets of data. Our team aims to predict the prices of the listings in Toronto, to allow homeowners to price their properties appropriately. Specifically, we seek to answer the following question: What prices should Airbnb suggest to their hosts given a set of features about the listing? This question is important because as more data becomes available, more intelligence can be extracted using modern machine learning tools. Therefore, it is worthwhile in exploring data driven analyses similar to those presented in this report as they are likely to improve experience for both hosts and customers, and ultimately add value to the company.Our team also try to cluster the listings in groups.

output:
  rticles::rjournal_article:
    includes:
      in_header: preamble.tex
   
---

```{r echo=FALSE, message=FALSE, warnings=FALSE}
# Clean all variables that might be left by other script to avoid collusion
rm(list=ls(all=TRUE))
# load required libraries
library(ggplot2) # plotting lib
library(gridExtra) # arrange grids
library(dplyr)  # data manipuation
library(RColorBrewer) # color palettes
library(tm) # text mining
library(dbscan) # density-based clustering
library(wordcloud) # plots fequent terms
library(factoextra) # deals with cluster plotting. Provides cluster related utility methods 
library(cluster) # for gower similarity and pam
library(plot3D) # 3D plots
library(summarytools)
library(purrr)
library(wordcloud2)
library(rworldmap)
library(lubridate)
library(VIM)
source('utils.R') # supplementary code
library(leaflet)
library(caret) # predictive models
library(plotly)
library( ggthemes)
th <- theme_fivethirtyeight() + theme(axis.title = element_text(), axis.title.x = element_text())
library(ggmap)
library(corrplot)
library(forcats)

# set summarytools global parameters
st_options(plain.ascii = F,       # This is very handy in all Rmd documents
      style = "rmarkdown",        # This too
      footnote = NA,             # Avoids footnotes which would clutter the result
      subtitle.emphasis = F,  # This is a setting to experiment with - according to
      dfSummary.graph.col = F
)  

# pick a palette
mainPalette = ggplotColours()
```

```{r global_options, include=FALSE}
# make the images flow nicely
knitr::opts_chunk$set(fig.pos = 'H', echo = T,comment = NA, prompt = F, 
                      cache = F, warning = F, message = F,  fig.align="center")
```


## Background

Airbnb has seen a meteoric growth since its inception in 2008 with the number of rentals listed on its website growing exponentially each year. Airbnb has successfully disrupted the traditional hospitality industry as more and more travellers, not just the ones who are looking for a bang for their buck but also business travellers resort to Airbnb as their premier accommodation provider.
Toronto has been one of the hottest markets for Airbnb in Canada, with over 26,000 listings as of Feb 2020. This means there are over 40 homes being rented out per square km in Toronto on Airbnb! One can perhaps attribute the success of Airbnb in Toronto to the high rates charged by the hotels, which are primarily driven by the exorbitant rental prices in the city.

## Objective


This study pursues two goals. The main objective is to predict the airbnb rental rate as accurate as possible. We will employ CRISP-DM methodology (Ref: \cite{mining}) and supervised learning approach, to achieve this goal.

We are also motivated to cluster the toronto airbnb listings in groups. The questions we will try to address are:

* If there are specific groups of listings that share similar features 
* If yes, how to use these group information for business.

To achieve the second goal we will use unsupervised learning approach.



# Apply the Ethical ML framework

## In the Problem definition and scope step

In the problem identification, we all agree in the group 9 that we want to develop a tool that help Airbnb's hosts to establish a rental price for a place as accurate as possible, also to cluster the existing listings based in similar features. we will be using several models of prediction and clustering.

Although individuals could be identified by its places, those are not negatively impacted, there is not any personal identification and we will not use aggregate information from another sources.

We can see that There could be a risk to individualize each person in the dataset if someone can access to another dataset that relate the the Host ID, the Hostname with the PII.

## In the Design step

To ensure we all interpreted the outputs of the model we clarify that we will find through the machine learning model selected, a sugested price for a place to rent in Toronto's Airbnb platform based in some features. 

## In the data collection and retention step

We just use data from the dataset AB_TOR_2019.

In the dataset there is no any underrepresented group because is a full data about hosts in Toronto, but could be some kind of bias about locations where people from some countries use to live.

## In data processing step

Although there is information in the data set that can be used for a proxy ethnic backgrounnd, the risk is low and could be helpfull for people looking for a place that match with own ethnicity.

We can identify a risk because we have some columns that could be used to re-identification, Host ID, Name and the location columns. The host id and name could be deleted to de-identify the data.

## In the model prototyping and QA testing step

The case we are working on, as is predicting prices for host services, is no so sensitive but the algorithms we are using for regression and clustering could be interpretable.

In order to make the model fairer and more accuracy, it is important to take care with the outliers in the prices so the model would be better adjusted.

## In the Deployment, Monitoring and Maintenance
When using the model it is good to monitor the performance of it when update the dataset to take into account possible business model changes like taxes policies that could originate that the predictions could be wrong.



# Data Analysis

This research employs the data set sourced from [Airbnb](http://insideairbnb.com/get-the-data.html). This real-life data comprises 26000 observations of the listing information of Toronto on Feb 14,2020.



## Data Dictionary


Column Name                   | Column Description  
------------------------------|----------------------------------------------------------------------------------
id                            | listing ID
name                          | Listing Title
host_id                       | ID of Host
host_name                     | Name of Host
neighbourhood_group           | Borough that contains listing
neighbourhood                 | Name of neighbourhood that listing is in
latitude                      | latitude coordinates of listing
longitude                     | longitude coordinates of listing
room_type                     | Type of public space that is being offered
price                         | price per night in dollars
minimum_nights                | minimum number of nights required to book listing
number_of_reviews             | total number of reviews that listing has accumulated
last_review                   | date in which listing was last reviewed
reviews_per_month             | total number of reviews divided by the number of months the listing is active
calculated_host_listings_count| amount of listing per host
availability_365              | number of days per year the listing is active

## Data Exploration

### Statistics

Firstly we are going to load and examine content and statistics of the data set

```{r}
data = read.csv("../data/AB_TOR_2019.csv", header = T, 
                na.strings = c("NA","","#NA"),sep=",")
```

```{r dataset_summary1, echo=FALSE, results="asis"}
print(dfSummary(data, valid.col = F, max.distinct.values = 3, heading = F),
      caption = "\\label{tab:dataset_summary1} Toronto Airbnb Dataset Summary", scalebbox = .9)
```

From the above summary, we can find that there are some negative values for Quantity and UnitPrice.These values don't make sense, so we'll delete them directly.

```{r}
#head(data)
#summary(data)
#str(data)
```
Table \ref{tab:dataset_summary} describes main statistical parameters of each column. Here is a look at the data sample.

```{r data_head, results='asis', echo=FALSE}
library(xtable) # nice table formats
print(xtable(data[1:12,1:8]), include.rownames = F, scalebox=.6)
print (xtable(data[1:12,9:16],
  caption = "\\label{tab:dataset_head} Toronto Airbnb Data Sample"), include.rownames = F,
  scalebox = .6)
```



###Missing data
```{r plot_notes2,  echo=FALSE, fig.align="center", fig.cap="Missing data"}

a = aggr(data)
plot(a)

```

```{r}
summary(a)
```
There are some missing data for neighbourhood_group,last_review and reviews_per_month.It's very strange that most of the neighbourhood_group miss in Toronto.We decide to ignore this feature. 

### Data Transformation

We need do some some data transformation.
```{r}
customerData <- data %>% 
  mutate( last_review= as.Date(last_review)) 
         
customerData <- customerData %>% 
  mutate( last_review= as.numeric(as.Date("2020-02-15")-last_review)) 

customerData <- customerData %>% 
  mutate( room_type= as.numeric(room_type) )

#customerData <- customerData %>% 
#  mutate(last_review = as.numeric(as.Date("2020-02-15")-last_review))

#glimpse(customerData)

```

We drop neighbourhood_group and other missing data.
```{r}

customerData1 = subset(customerData,select = -neighbourhood_group)
customerData1 = customerData1 %>%filter(complete.cases(.)) 
glimpse(customerData1)
#b = aggr(customerData1)
#plot(b)

```
###data visualization
```{r results='hold'}
# histogram with added parameters
hist(customerData1$number_of_reviews,
main="number_of_reviews",
xlab="number_of_reviews",
breaks=10000,
xlim=c(0,300),
col="darkmagenta",
freq=FALSE
)
```


```{r results='hold'}
# histogram with added parameters
hist(customerData1$last_review,
main="last_review",
xlab="last_review",
breaks=10000,
xlim=c(0,300),
col="darkmagenta",
freq=FALSE
)
```

```{r results='hold'}
# histogram with added parameters
hist(customerData1$availability_365,
main="availability_365",
xlab="availability_365",
breaks=10000,
xlim=c(0,300),
col="darkmagenta",
freq=FALSE
)
```
Hosts on Airbnb offer a wide variety of spaces, ranging from shared rooms to private islands.

All homes are grouped into the following three room types:

Entire place
Private room
Shared room
hotel room

Entire place
Entire places are best if you're seeking a home away from home. With an entire place, you'll have the whole space to yourself. This usually includes a bedroom, a bathroom, a kitchen, and a separate, dedicated entrance. Hosts should note in the description if they'll be on the property or not (e.g.: "Host occupies first floor of the home"), and provide further details on the listing.

Private rooms
Private rooms are great for when you prefer a little privacy, and still value a local connection. When you book a private room, you'll have your own private room for sleeping and may share some spaces with others. You might need to walk through indoor spaces that another host or guest may occupy to get to your room.

Shared rooms
Shared rooms are for when you don't mind sharing a space with others. When you book a shared room, you'll be sleeping in a space that is shared with others and share the entire space with other people. Shared rooms are popular among flexible travellers looking for new friends and budget-friendly stays.
```{r }
room = customerData1 %>%
  group_by(room_type = factor(room_type, labels = c("Entire home/apt","Hotel room","Private room","Shared room")))  %>%
  summarise(COUNT = n())
p1 = ggplot(room,aes(x=room_type, y = COUNT, fill = room_type)) + 
      geom_bar(stat = "identity", alpha = 0.7) +  theme(axis.text.x=element_blank(),
      axis.ticks.x=element_blank())
plot(p1)
```

```{r }
mytable <- table(customerData1$room_type)
lbls <-  c("Entire home/apt","Hotel room","Private room","Shared room")
pie(mytable, labels = lbls,col=rainbow(length(lbls)),
   main="Pie Chart of room")
   
```   

Price
The most important (target) variable is price.

```{r }

ggplot(customerData1, aes(price)) +
  geom_histogram(bins = 30, aes(y = ..density..), fill = "purple") + 
  geom_density(alpha = 0.2, fill = "purple") +
  th +
  ggtitle("Distribution of price",
          subtitle = "The distribution is very skewed") +
  theme(axis.title = element_text(), axis.title.x = element_text()) +
  geom_vline(xintercept = round(mean(customerData1$price), 2), size = 2, linetype = 3)


```

Histogram & Density with log10 transformation
Since the original distribution is very skewed, logarithmic transformation can be used to gain better insight into data.
```{r }
ggplot(customerData1, aes(price)) +
  geom_histogram(bins = 30, aes(y = ..density..), fill = "purple") + 
  geom_density(alpha = 0.2, fill = "purple") +
  th +
  ggtitle("Transformed distribution of price",
          subtitle = expression("With" ~'log'[10] ~ "transformation of x-axis")) +
  #theme(axis.title = element_text(), axis.title.x = element_text()) +
  geom_vline(xintercept = round(mean(customerData1$price), 2), size = 2, linetype = 3) +
  scale_x_log10() #+
  #annotate("text", x = 1800, y = 0.75,label = paste("Mean price = ", paste0(round(mean(customerData1$price), 2), "$")),
  #         color =  "#32CD32", size = 8)
```

Price & Availability
```{r }
ggplot(customerData1, aes(availability_365, price)) +
  th +
  geom_point(alpha = 0.2, color = "slateblue") +
  geom_density(stat = "identity", alpha = 0.2) +
  xlab("Availability during year") +
  ylab("Price") +
  ggtitle("Relationship between availability",
          subtitle = "there is not clear relationship") 



```

It’s hard to see clear pattern, but there’s a lot of expensive objects with few available days and many available days.

Price & Number Of Reviews
```{r }
ggplot(customerData1, aes(number_of_reviews, price)) +
  th + theme(axis.title = element_text(), axis.title.x = element_text()) +
  geom_point(aes(size = price), alpha = 0.05, color = "slateblue") +
  xlab("Number of reviews") +
  ylab("Price") +
  ggtitle("Relationship between number of reviews",
          subtitle = "The most expensive objects have small number of reviews (or 0)")


```

```{r }

df  <- customerData1  %>% select("price","number_of_reviews","minimum_nights")
cor(df)
corrplot(cor(df))

```
Below is a plot of the top 10 neighborhoods by number of listings. 

```{r }

customerData1 %>%
    group_by(neighbourhood) %>%
    summarize(num_listings = n(), 
              borough = unique(neighbourhood)) %>%
    top_n(n = 10, wt = num_listings) %>%
    ggplot(aes(x = fct_reorder(neighbourhood, num_listings), 
               y = num_listings, fill = borough)) +
    geom_col() +
    coord_flip() +
    theme(legend.position = "bottom") +
    labs(title = "Top 10 neighborhoods by no. of listings",
         x = "Neighborhood", y = "No. of listings")

```

The plot below shows the distribution of price by room type. (Note that the y-axis is on a log scale.) There is much variation in price within each room type. Overall, it looks like “Entire home/apt” listings are slightly pricier than “Private room”, which in turn are more expensive than “Shared room”. This makes intuitive sense.
```{r }
ggplot(data, aes(x = room_type, y = price)) +
    geom_violin() +
    scale_y_log10()

```

Map of the top 20 most expensive listings
```{r }

# get top 20 listings by price
top_df <- customerData1 %>% top_n(n = 20, wt = price)

# get background map
top_height <- max(top_df$latitude) - min(top_df$latitude)
top_width <- max(top_df$longitude) - min(top_df$longitude)
top_borders <- c(bottom  = min(top_df$latitude)  - 0.1 * top_height,
                 top     = max(top_df$latitude)  + 0.1 * top_height,
                 left    = min(top_df$longitude) - 0.1 * top_width,
                 right   = max(top_df$longitude) + 0.1 * top_width)

top_map <- get_stamenmap(top_borders, zoom = 12, maptype = "toner-lite")

# map of top 50 most expensive
ggmap(top_map) +
    geom_point(data = top_df, mapping = aes(x = longitude, y = latitude,
                                        col = price)) +
    scale_color_gradient(low = "blue", high = "red")


```

Median price by neighborhood
In the map below, each dot is one neighborhood. The size of the dot depends on the number of listings and the color of the dot depends on the median price in that neighborhood.

```{r }
nhd_df <- customerData1 %>%
    group_by(neighbourhood) %>%
    summarize(num_listings = n(),
              median_price = median(price),
              long = median(longitude),
              lat = median(latitude),
              borough = unique(neighbourhood))
# map of all listings: one point per neighborhood
height <- max(customerData1$latitude) - min(customerData1$latitude)
width <- max(customerData1$longitude) - min(customerData1$longitude)
borders <- c(bottom  = min(customerData1$latitude)  - 0.1 * height,
             top     = max(customerData1$latitude)  + 0.1 * height,
             left    = min(customerData1$longitude) - 0.1 * width,
             right   = max(customerData1$longitude) + 0.1 * width)

map <- get_stamenmap(borders, zoom = 11, maptype = "toner-lite")
ggmap(map) +
    geom_point(data = nhd_df, mapping = aes(x = long, y = lat,
                                            col = median_price, size = num_listings)) +
    scale_color_gradient(low = "blue", high = "red")
```

### Descriptive Features.

*name * is free-text features that might provide additional insights about the listing. We are going to take a close look at this feature and decide if we could utilize it.

Lets' begin with the *name*
```{r plot_notes,  echo=FALSE, fig.align="center", fig.cap="Most Common Words in Description"}
description = data %>%  mutate(text = trimws(name)) %>% filter(!is.na(text)) %>% select(text)
pCorups = VCorpus(VectorSource(description))
pCorups  = tm_map(pCorups , removeNumbers)
pCorups  = tm_map(pCorups , removePunctuation)
pTermMatrix = tm::TermDocumentMatrix(pCorups)
tmp = as.matrix(pTermMatrix)
tmp = sort(rowSums(tmp),decreasing=T)
tmp = data.frame(word = names(tmp),freq=tmp)
set.seed(5673)
wordcloud(words = tmp$word, freq = tmp$freq, min.freq = 70,max.words=80, random.order=F,
          rot.per=0.35, colors=mainPalette)

#set.seed(5673)
#wordcloud2(data = tmp, size = 2)
```
From the word cloud, we can get some highly frequently used words such as downtown,bedroom,room,condo,private,apartment.

Unfortunately *name* feature does not provide more knowledge to what the others features already supply. Thus it will be dropped.


# Regression Models and Model Performance Evalutation

In this section we will apply various clustering methods to cluster the customer based rfm. We will use Partitioning clustering and Hierarchical clustering approaches. 


```{r}
airbnb_train <- customerData1 %>% sample_frac(.7) %>% filter(price > 0)
airbnb_test  <- anti_join(customerData1, airbnb_train, by = 'id') %>% filter(price > 0)

```

##1st Linear Regression model
```{r}
first_model <- train(price ~ latitude + longitude + room_type + minimum_nights  + availability_365 , data = airbnb_train, method = "lm")
summary(first_model)

```
This model is not so good. Median residual error is -22.9, while it should be near 0. R2=0.06 is also not so good.

Let’s plot the first model.
```{r plot_feature_selection1,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap="Number of Predictors vs Accuracy", out.width="1.1\\linewidth"}
plot(first_model$finalModel)


```
##2nd Linear Regression model
```{r}

learn <- airbnb_train %>% filter(price < quantile(airbnb_train$price, 0.9) & price > quantile(airbnb_train$price, 0.1)) %>% tidyr::drop_na()
second_model <- lm(log(price) ~ room_type + latitude + longitude 
                        + number_of_reviews + availability_365
                       + reviews_per_month + 
                     calculated_host_listings_count + minimum_nights, data = learn)
# Summarize the results
summary(second_model)

```
This model is an improvement. Median residual error is now -0.014, which is far better than -22.9 from the first model. R2=0.371 means that this model explains about 50% variance of target variable.
Obviously we choose the second model for the prediction.
```{r plot_feature_selection,  echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", fig.cap="Number of Predictors vs Accuracy", out.width="1.1\\linewidth"}
plot(second_model)
```

##Predict prices for training set

```{r echo=FALSE}
airbnb_test <- airbnb_test %>% filter(price <= quantile(airbnb_train$price, 0.9) & price >= quantile(airbnb_train$price, 0.1)) %>% tidyr::drop_na()
pred_regression <- predict(second_model, newdata = airbnb_test)
pred_regression <- exp(pred_regression)

RMSE_regression <- sqrt(mean( (airbnb_test$price - pred_regression)**2 ))

SSE <- sum((airbnb_test$price - pred_regression)**2)
SSR <- sum((pred_regression - mean(airbnb_test$price)) ** 2)
R2 <- 1 - SSE/(SSE + SSR)
RMSE_regression

R2

regression_results <- tibble(
  obs = airbnb_test$price,
  pred = pred_regression,
  diff = pred - obs,
  abs_diff = abs(pred - obs),
  neighbourhood = airbnb_test$neighbourhood,
  name = airbnb_test$name,
  type = airbnb_test$room_type
  
)

regression_plot <- regression_results %>% 
  ggplot(aes(obs, pred)) +
geom_point(alpha = 0.1, aes(text = paste("Name:", name, "\nType:", type,
                                           "\nPrice diff = ", diff))) +
  th +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Observed vs predicted",
          subtitle = "Linear regression model") + 
  geom_abline(slope = 1, intercept = 0, color = "blue", linetype = 2)  +
  facet_wrap(~type)

```
```{r echo=FALSE}

ggplotly(regression_plot)

```

# Undertanding the listing Employing Unsupervised Learning

In this section we will apply various clustering methods to cluster the listings in several groups. We will use Partitioning clustering and Hierarchical clustering approaches. 

Before we apply clustering models to the dataset we should assess clustering tendency. In order to do so we will employ **Hopkins** statistics.

## Hopkins Statistics

Hopkins statistic is used to assess the clustering tendency of a dataset by measuring the probability that a given dataset is generated by a uniform data distribution.(Ref: \cite{mining}).
Let's calculate Hopkins (**H**) statistics for customerData1:

The **H** value close to one indicates very good clustering tendency. The **H** value around or greater than 0.5 denotes poor clustering tendency(Ref: \cite{factoextra}). 
```{r}

customerData2 = subset(customerData1,select = -id)
customerData2 = subset(customerData2,select = -name)
customerData2 = subset(customerData2,select = -host_id)
customerData2 = subset(customerData2,select = -host_name)
customerData2 = subset(customerData2,select = -neighbourhood)

customerData2 <- customerData2 %>% 
mutate(
       latitude = scale(latitude),
       longitude = scale(longitude),
       price = scale(price),
       minimum_nights = scale(minimum_nights),
       number_of_reviews = scale(number_of_reviews),
       last_review = scale(last_review),
       reviews_per_month  = scale(reviews_per_month ),
       calculated_host_listings_count = scale(calculated_host_listings_count),
       availability_365 = scale(availability_365)
)
#summary(customerData2)

```
```{r}
H =  get_clust_tendency(customerData2,n = 100, graph = F, seed = 6709)
print(H[["hopkins_stat"]])
```
Perfect! H value is very close to 1. The dataset is clustrable.

## Partitioning Clustering Approach 

At first, we use Elbow method to get optimal number of clusters for k-means clustering:
```{r }

set.seed(123)
# Elbow method
fviz_nbclust(customerData2, kmeans, method = "wss") +
    geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "Elbow method")

```

It seems that the optimal number of clusters is 4.

Let's use kmeans to cluster the dataset.

```{r results='hold'}
set.seed(123)
k2 <- kmeans(customerData2, centers = 4, nstart = 25)
#k2
fviz_cluster(k2, data = customerData2)


```

```{r results='hold'}
group <- k2$cluster
customerData3 <- cbind(customerData1, group)
#write.csv(customerData3, "../shiny/www/mydata1.csv")

```

## Hierarchical clustering approache 

```{r results='hold'}
set.seed(123)
d <- dist(customerData2)
c <- hclust(d, method = 'ward.D2')

plot(c)
```


```{r results='hold'}
members <- cutree(c,k = 4)

table(members)
#members
```
We decide to accept the kmeans cluster result.
K-means clustering with 4 clusters of sizes group1 = 2649, group2 = 9925, group3 = 2800, group4 = 3649
```{r results='hold'}
group1 <- customerData3 %>% 
  filter(group == 1)

group2 <- customerData3 %>% 
  filter(group == 2)

group3 <- customerData3 %>% 
  filter(group == 3)

group4 <- customerData3 %>% 
  filter(group == 4)

```
Let's dig out why the listings are clustered to 4 groups.
At first, let's observe every group's geographic distribution.
```{r, fig.height=7}
leaflet(group1 %>% select(longitude,latitude)) %>%
  setView(lng = -79.38, lat = 43.75,zoom = 11) %>%
   addTiles() %>% 
  addMarkers(
  clusterOptions = markerClusterOptions())
```

```{r, fig.height=7}
leaflet(group2 %>% select(longitude,latitude)) %>%
  setView(lng = -79.38, lat = 43.75,zoom = 11) %>%
   addTiles() %>% 
  addMarkers(
  clusterOptions = markerClusterOptions())
```

```{r, fig.height=7}
leaflet(group3 %>% select(longitude,latitude)) %>%
  setView(lng = -79.38, lat = 43.75,zoom = 11) %>%
   addTiles() %>% 
  addMarkers(
  clusterOptions = markerClusterOptions())
```

```{r, fig.height=7}
leaflet(group4 %>% select(longitude,latitude)) %>%
  setView(lng = -79.38, lat = 43.75,zoom = 11) %>%
   addTiles() %>% 
  addMarkers(
  clusterOptions = markerClusterOptions())
```

From the geographic distribution, we can observe that group4, most of the listings are far from downtown.

Let's observe every group's price distribution.

```{r results='hold'}
# histogram with added parameters
hist(group1$price,
main="group1Price",
xlab="group1Price",
breaks=100000,
xlim=c(0,500),
col="darkmagenta",
freq=FALSE
)
```

```{r results='hold'}
# histogram with added parameters
hist(group2$price,
main="group2Price",
xlab="group2Price",
breaks=100000,
xlim=c(0,500),
col="darkmagenta",
freq=FALSE
)
```

```{r results='hold'}
# histogram with added parameters
hist(group3$price,
main="group3Price",
xlab="group3Price",
breaks=100000,
xlim=c(0,500),
col="darkmagenta",
freq=FALSE
)
```

```{r results='hold'}
# histogram with added parameters
hist(group4$price,
main="group4Price",
xlab="group4Price",
breaks=100000,
xlim=c(0,500),
col="darkmagenta",
freq=FALSE
)
```
Obviously in group4, The vast majority of rental prices are concentrated below 100$.

Let's list every group's median price. 

```{r }
median(group1$price)
median(group2$price)
median(group3$price)
median(group4$price)

```
In group1, the rental price is median.
Group4 is the cheapest.
Group2 & Group3 has the same median price.

We're interested in what's the difference between group2 and group3.
Let's dig it further.


```{r results='hold'}
# histogram with added parameters
hist(group2$minimum_nights,
main="group2 minimum_nights",
xlab="minimum_nights",
breaks=10000,
xlim=c(0,100),
col="darkmagenta",
freq=FALSE
)
```

```{r results='hold'}
# histogram with added parameters
hist(group3$minimum_nights,
main="group3 minimum_nights",
xlab="minimum_nights",
breaks=10000,
xlim=c(0,100),
col="darkmagenta",
freq=FALSE
)
```

```{r results='hold'}
# histogram with added parameters
hist(group2$number_of_reviews,
main="group2 number_of_reviews",
xlab="minimum_nights",
breaks=10000,
xlim=c(0,500),
col="darkmagenta",
freq=FALSE
)
```

```{r results='hold'}
# histogram with added parameters
hist(group3$number_of_reviews,
main="group3 number_of_reviews",
xlab="number_of_reviews",
breaks=10000,
xlim=c(0,500),
col="darkmagenta",
freq=FALSE
)
```

It seems that the group3 has more reviews that group2.

```{r results='hold'}
# histogram with added parameters
hist(group2$last_review,
main="group2 last_review",
xlab="last_review",
breaks=10000,
xlim=c(0,200),
col="darkmagenta",
freq=FALSE
)
```

```{r results='hold'}
# histogram with added parameters
hist(group3$last_review,
main="group3 last_review",
xlab="last_review",
breaks=10000,
xlim=c(0,200),
col="darkmagenta",
freq=FALSE
)
```

```{r results='hold'}
# histogram with added parameters
hist(group2$availability_365,
main="group2 availability_365",
xlab="last_review",
breaks=10000,
xlim=c(0,200),
col="darkmagenta",
freq=FALSE
)
```

```{r results='hold'}
# histogram with added parameters
hist(group3$availability_365,
main="group3 availability_365",
xlab="last_review",
breaks=10000,
xlim=c(0,200),
col="darkmagenta",
freq=FALSE
)
```
It seems that the group3 has more availability_365 that group2.
Let's summarize every group's characteristic.

Group1: the rental rate is median.
Group2: the rental rate is high, and the attention is low because there are less reviews in this group.Since most of listings in this group are located in downtown,they have Convenient transportation.
Group3: the rental rate is high, and the attention is high because there are more reviews in this group.Since most of listings in this group are located in downtown,they have Convenient transportation.
Group4: the rental rate is low.

Some potential business value:
Airbnb can recommeded the listings in group 4 for the customers that have high price sensetivity.
The listings in group2 can be recommended to the customers that prefer the convenient transportation and don't mind the attention.
The listings in group3 can be recommended to the customers that prefer the convenient transportation and the high attention.
The listings in group4 can be recommended to other customers.

# Model Deployment


In our second regression model, metrics for testing set: R2=0.285 and RMSE=42.18. Is it good enough? It is hard to tell. We feel
that the model meets our first objective, which is prediction of toronto airbnb rental rate.
The second logistic regression model we picked is more accurate.
The model is fast and easy to deploy. Due to the nature of the business the model does require frequent data updates and
re-training.
We are also very satisfied with accomplishment of our second goal, which is understanding of the
listing. We believe that clustering make sense for business.

# Conclusion

Through exploring toronto airbnb listings dataset collected in 2020 we were able to come up with two models. One is a linear regression model,that predicts the property owner's rental rate. The second model provides in-depth view of the listings.  

The study started with thorough analysis of the data set. At this phase we were able to identified many interesting patterns that insured the success of the whole project. We commenced our research providing descriptive stats on all available features of the data set. 

Then we applied and evaluated two supervised learning algorithms: two kinds of Logistic Regression.

Lastly we applied unsupervised learning to understand how to cluster the listings in groups and find the potential business value.

As a result of this study we fully understood the data we dealt with. We designed reasonably accurate rental rate prediction model. We managed to group the listings into meaningful, highly interpretable clusters that explain the property's characteristics well.

Overall we believe we have achieved all our goals. 



\bibliography{RJreferences}


# Note from the Authors

This file was generated using [_The R Journal_ style article template](https://github.com/rstudio/rticles), additional information on how to prepare articles for submission is here - [Instructions for Authors](https://journal.r-project.org/share/author-guide.pdf). The article itself is an executable R Markdown file that could be [downloaded from Github](https://github.com/ivbsoftware/big-data-final-2/blob/master/docs/R_Journal/big-data-final-2/) with all the necessary artifacts.
